---
layout: post
title: kafka消息消费延迟
category: code
---

# 背景
使用的消息中间件是kafka，业务上新增反馈数据，但是测试的时候数据始终没有变化，没有接收到消息。

<br>

# 排查过程

![rts日志流程](https://raw.githubusercontent.com/imekaku/MyPicture/master/github-blog-pic/2019-04-25-rts-log-kafka.png)

日志的流动过程其实并不复杂，但是很诡异的是就是查不到消息。

推荐下发请求是ok的，抓包看了客户端的上报也是ok的，rts日志那边好像也没有问题，而且我这边好像也能断断续续的收到一些请求。我就怀疑是日志丢了一些，或者中间某一个地方我都日志变了，因为我使用『日志采集计算服务calculate』获取得到的日志中的recoid 和 用户id去查今天的pv日志都没有。后来发现也是没问题的。

然后我从日志采集计算服务中的INFO日志，发现：

```txt
[ForkJoinPool.commonPool-worker-57] INFO  o.a.k.c.consumer.internals.Fetcher - Fetch offset 11082073049 is out of range for partition vmate_online_merge_log-0, resetting offset
```

因为是info级别的日志我起初也没有在意，后来排查发现有这个日志说明没有这个偏移量的消息，要么已经消费光了，offset大于当前的了，要么消息被删了。
然后我把采集到的日志信息中的时间戳拿出来，发现是3天前的，因为kafka的落地日志是保留三天，所以如果这个服务消费三天前的，并且在kafka删除了落地日志之后再去消费这个offset的话，那就会报错。

然后从kafka manager里面看到确实是这样：
![kafka-manager](https://raw.githubusercontent.com/imekaku/MyPicture/master/github-blog-pic/2019-04-25-kafka-manager-view.jpeg)

原因是日志采集服务消费得太慢，生产得太快。后面把消费者优化之后消息就逐渐减少了。




